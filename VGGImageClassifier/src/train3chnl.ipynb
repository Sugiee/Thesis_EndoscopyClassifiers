{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class processDataset():\n",
    "    def __init__(self, datasetPath, resize_size):\n",
    "        # Data augmentation and normalisation\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((resize_size, resize_size)),                      # Resizing for VGG input\n",
    "            transforms.ToTensor(),                                              # Convert to tensor\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalisation\n",
    "        ])\n",
    "        \n",
    "        # Use ImageFolder to load dataset:\n",
    "        self.fullDataset = datasets.ImageFolder(root=datasetPath, transform=transform)        \n",
    "\n",
    "        # Extract labels\n",
    "        labels = [label for _, label in self.fullDataset]\n",
    "\n",
    "        # Perform stratified split\n",
    "        train_indices, val_indices = train_test_split(\n",
    "            range(len(self.fullDataset)), test_size=0.2, stratify=labels, random_state=42\n",
    "        )\n",
    "\n",
    "        # Create subsets\n",
    "        train_dataset = torch.utils.data.Subset(self.fullDataset, train_indices)\n",
    "        val_dataset = torch.utils.data.Subset(self.fullDataset, val_indices)            \n",
    "\n",
    "        # Compute class weights using scikit-learn\n",
    "        train_labels = [self.fullDataset[idx][1] for idx in train_indices]\n",
    "        self.class_weights = compute_class_weight(\n",
    "            class_weight=\"balanced\",\n",
    "            classes=np.unique(train_labels),\n",
    "            y=train_labels\n",
    "        )\n",
    "        \n",
    "        self.class_weights = torch.tensor(self.class_weights, dtype=torch.float32).to(device)\n",
    "        print(\"Class weights:\", self.class_weights)        \n",
    "\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=2)\n",
    "        self.val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=2) \n",
    "\n",
    "datasetPath = r\"\"\n",
    "dataset = processDataset(datasetPath, 224)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualGeometryGroup(nn.Module):\n",
    "    def __init__(self, output_dim, resize_size):\n",
    "        super(VisualGeometryGroup, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),    # Conv64\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPool\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Conv128\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPool\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), # Conv256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), # Conv256\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPool\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1), # Conv512\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), # Conv512\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPool\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), # Conv512\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), # Conv512\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),         # MaxPool\n",
    "        )        \n",
    "        \n",
    "        self.classifier = nn.Sequential(            \n",
    "            nn.Linear(512 * int(resize_size // 32) * int(resize_size // 32), 4096),  # Adjust based on input size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_sizes = [ 8, 16, 32]\n",
    "resize_sizes = [128, 224, 256, 320] # 128, 224, 256, 320\n",
    "learning_rates = [0.01, 0.001, 0.0001, 0.00001] # 0.01, 0.001, 0.0001, 0.00001\n",
    "epochs = 20\n",
    "patience = 3\n",
    "\n",
    "# Generate all combinations\n",
    "hyperparameter_combinations = list(itertools.product(batch_sizes, resize_sizes, learning_rates))\n",
    "\n",
    "# Base directory where output folders will be created\n",
    "datasetPath = r\"\"\n",
    "base_output_dir = r\"\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# Global trackers for the best result\n",
    "maxValAcc = 0.0\n",
    "maxValAccFolder = None\n",
    "prevResize_Size = 0\n",
    "\n",
    "# Iterate over hyper-parameter combinations\n",
    "for index, (batch_size, resize_size, lr) in enumerate(hyperparameter_combinations):    \n",
    "    folderName = f\"{index + 1:03d}\"  # e.g., '001', '002', etc.\n",
    "    newFolderPath = os.path.join(base_output_dir, folderName)\n",
    "    os.makedirs(newFolderPath, exist_ok=True)\n",
    "    \n",
    "    # Logging\n",
    "    epochLogs = []\n",
    "    reportText = []\n",
    "    reportText.append(\"Hyperparameters and Results\\n\" + \"=\"*40)\n",
    "    reportText.append(f\"Batch Size: {batch_size}\")\n",
    "    reportText.append(f\"Learning Rate: {lr}\")\n",
    "    reportText.append(f\"Image resize: {resize_size}\\n\")\n",
    "    \n",
    "    print(f\"Running combination {index + 1}: Batch Size={batch_size}, LR={lr}, resize={resize_size}\")\n",
    "    \n",
    "    # re-initialise dataset only when resize_size changes\n",
    "    if prevResize_Size != resize_size:\n",
    "        dataset = processDataset(datasetPath, resize_size) # saves time by executing only when needed\n",
    "    prevResize_Size = resize_size\n",
    "    \n",
    "    # Initialise model and lossFn, optimiser\n",
    "    model = VisualGeometryGroup(output_dim=5, resize_size=resize_size).to(device)\n",
    "    lossFn = nn.CrossEntropyLoss(weight=dataset.class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)        \n",
    "    \n",
    "    # Variables for early stopping\n",
    "    bestValAccuracyForConfig = 0.0\n",
    "    bestModelStateForConfig = copy.deepcopy(model.state_dict())\n",
    "    epochsNoImprove = 0\n",
    "    \n",
    "    # Train and validate model\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total   = 0\n",
    "        train_loss_total = 0.0\n",
    "        \n",
    "        for Xbatch, ybatch in dataset.train_loader:\n",
    "            Xbatch, ybatch = Xbatch.to(device), ybatch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(Xbatch)\n",
    "            loss = lossFn(y_pred, ybatch)            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            predictions = torch.argmax(y_pred, dim=1)\n",
    "            train_correct += (predictions == ybatch).sum().item()\n",
    "            train_total   += ybatch.size(0)\n",
    "            train_loss_total += loss.item()                 \n",
    "        \n",
    "        # Training accuracy for the epoch\n",
    "        train_accuracy = (train_correct / train_total) * 100.0\n",
    "        train_loss_avg = train_loss_total / len(dataset.train_loader)            \n",
    "        \n",
    "        # Validate & save outputs\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        numValSamples = 0\n",
    "        val_loss_total = 0.0        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for Xval, yval in dataset.val_loader:\n",
    "                Xval, yval = Xval.to(device), yval.to(device)\n",
    "                \n",
    "                y_pred_val = model(Xval)\n",
    "                \n",
    "                # Calculate validation loss & accuracy\n",
    "                val_loss_total += lossFn(y_pred_val, yval).item()                                    \n",
    "                val_predictions = torch.argmax(y_pred_val, dim=1)\n",
    "                val_correct += (val_predictions == yval).sum().item()\n",
    "                numValSamples += yval.size(0)                                \n",
    "        \n",
    "        val_accuracy = 100.0 * val_correct / numValSamples\n",
    "        val_loss_avg = val_loss_total / len(dataset.val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Acc: {train_accuracy:.4f}%, Train loss: {train_loss_avg:.4f}, \"\n",
    "                                          f\"Val Acc: {val_accuracy:.4f}%, Val loss: {val_loss_avg:.4f}\")        \n",
    "        epoch_line = (f\"Epoch {epoch+1}/{epochs}, \"\n",
    "                      f\"Train Acc: {train_accuracy:.4f}%, \" f\"Train loss: {train_loss_avg:.4f}, \"\n",
    "                      f\"Val Acc: {val_accuracy:.4f}%, \" f\"Val loss: {val_loss_avg:.4f}\")\n",
    "        epochLogs.append(epoch_line)\n",
    "        \n",
    "        # Check if this is the best validation accuracy so far for curr config\n",
    "        if val_accuracy > bestValAccuracyForConfig:\n",
    "            bestValAccuracyForConfig = val_accuracy\n",
    "            bestModelStateForConfig = copy.deepcopy(model.state_dict())\n",
    "            epochsNoImprove = 0\n",
    "        else:\n",
    "            epochsNoImprove += 1\n",
    "\n",
    "        # Early stopping check\n",
    "        if epochsNoImprove >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1} (no improvement in {patience} consecutive epochs).\")\n",
    "            break\n",
    "    \n",
    "    # Inference    \n",
    "    model.load_state_dict(bestModelStateForConfig)\n",
    "    \n",
    "    # Evaluate on the validation set using the best model\n",
    "    model.eval()\n",
    "    valPredsList  = []\n",
    "    valLabelsList = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            for Xval, yval in dataset.val_loader:\n",
    "                Xval, yval = Xval.to(device), yval.to(device)\n",
    "                \n",
    "                y_pred_val = model(Xval)                                                                                  \n",
    "                val_predictions = torch.argmax(y_pred_val, dim=1)                \n",
    "                                \n",
    "                valPredsList.extend(val_predictions.cpu().numpy())\n",
    "                valLabelsList.extend(yval.cpu().numpy())                        \n",
    "\n",
    "    # Confusion matrix & classification report\n",
    "    valPredsArray  = np.array(valPredsList)\n",
    "    valLabelsArray = np.array(valLabelsList)\n",
    "    \n",
    "    # Identify which classes actually appear in validation\n",
    "    valClassesInUse = np.unique(valLabelsArray)\n",
    "    \n",
    "    # Map numeric labels (0,1,2,...) to string names\n",
    "    valLabelsNameArray = dataset.val_loader.dataset.dataset.classes\n",
    "    matchedValLabelsNameArray = [valLabelsNameArray[i] for i in valClassesInUse]\n",
    "    \n",
    "    valConfMatrix = confusion_matrix(\n",
    "        valLabelsArray,\n",
    "        valPredsArray,\n",
    "        labels=valClassesInUse\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 8))      # Increase figure size for large # of classes\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=valConfMatrix,\n",
    "        display_labels=matchedValLabelsNameArray\n",
    "    )\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')    \n",
    "    confusionMatrixPath = os.path.join(newFolderPath, \"confusion_matrix.png\")\n",
    "    plt.savefig(confusionMatrixPath, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Classification report\n",
    "    stringLabelsForReport = [matchedValLabelsNameArray[i] for i in valClassesInUse]\n",
    "    class_report = classification_report(\n",
    "        valLabelsArray,\n",
    "        valPredsArray,\n",
    "        labels=valClassesInUse,        \n",
    "        target_names=stringLabelsForReport,\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Compute per-class TP/FP/FN/TN\n",
    "    total_samples = valConfMatrix.sum()\n",
    "    tp_fp_fn_tn_lines = [\"Per-Class TP/FP/FN/TN:\"]\n",
    "        \n",
    "    for i, class_label in enumerate(valClassesInUse):\n",
    "        TP = valConfMatrix[i, i]\n",
    "        FP = valConfMatrix[:, i].sum() - TP\n",
    "        FN = valConfMatrix[i, :].sum() - TP\n",
    "        TN = total_samples - (TP + FP + FN)\n",
    "        \n",
    "        line = (f\"Class {class_label} --> \"\n",
    "                f\"TP: {TP}, FP: {FP}, FN: {FN}, TN: {TN}\")\n",
    "        tp_fp_fn_tn_lines.append(line)\n",
    "        \n",
    "    tp_fp_fn_tn_report = \"\\n\".join(tp_fp_fn_tn_lines)\n",
    "    \n",
    "    # Update global best if improved\n",
    "    if bestValAccuracyForConfig > maxValAcc:\n",
    "        maxValAcc = bestValAccuracyForConfig\n",
    "        maxValAccFolder = index + 1 # +1 so it matches folder numbering\n",
    "    \n",
    "    # Combine everything into a SINGLE text file   \n",
    "   \n",
    "    reportText.append(\"Epoch Logs:\")\n",
    "    reportText.extend(epochLogs)\n",
    "    reportText.append(f\"\\n\")\n",
    "    \n",
    "    reportText.append(f\"Global Best Accuracy So Far: {maxValAcc:.4f}%\")\n",
    "    reportText.append(f\"Folder with Global Best Accuracy So Far: {maxValAccFolder}\\n\")\n",
    "\n",
    "    # confusion matrix text\n",
    "    maxLabelLength = max(len(lbl) for lbl in matchedValLabelsNameArray)\n",
    "    # Header\n",
    "    # header = \" \" * (maxLabelLength + 1)\n",
    "    # for label in matchedValLabelsNameArray:\n",
    "    #     header += f\"{label:>5} \"\n",
    "    # reportText.append(header)\n",
    "\n",
    "    # Rows\n",
    "    for row_label, row_values in zip(matchedValLabelsNameArray, valConfMatrix):\n",
    "        row_str = f\"{row_label:<{maxLabelLength}} \"\n",
    "        for val in row_values:\n",
    "            row_str += f\"{val:>5} \"\n",
    "        reportText.append(row_str)\n",
    "\n",
    "    reportText.append(\"\")  # blank line\n",
    "    \n",
    "    # Classification report\n",
    "    reportText.append(\"Classification Report:\")\n",
    "    reportText.append(class_report)\n",
    "    \n",
    "    # Per-class TP/FP/FN/TN\n",
    "    reportText.append(tp_fp_fn_tn_report)\n",
    "    \n",
    "    final_report = \"\\n\".join(reportText)\n",
    "\n",
    "    # Save to a text file\n",
    "    combined_report_path = os.path.join(newFolderPath, \"combinedReport.txt\")\n",
    "    with open(combined_report_path, \"w\") as f:\n",
    "        f.write(final_report)\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(newFolderPath, \"model.pth\")\n",
    "    torch.save(bestModelStateForConfig, model_path)\n",
    "\n",
    "print(\"Grid search complete!\")\n",
    "print(f\"Best accuracy overall: {maxValAcc:.4f}%\")\n",
    "print(f\"Best folder overall: {maxValAccFolder}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
